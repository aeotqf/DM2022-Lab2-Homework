{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c26ba0",
   "metadata": {},
   "source": [
    "5) NN from the lab - This I tried with the original data and the Preproccess data, and changing a little bit some things like adding layers, batch size and epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44dbad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "# importing some libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8197f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "training_data4 = pd.read_csv('data/training_data.csv')\n",
    "test_data4 = pd.read_csv('data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f39766dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ellis\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_features=5000,\n",
       "                tokenizer=<function word_tokenize at 0x0000029DB39ADC10>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# build analyzers (bag-of-words)\n",
    "BOW_500 = CountVectorizer(max_features=5000,tokenizer=nltk.word_tokenize) \n",
    "\n",
    "# apply analyzer to training data\n",
    "BOW_500.fit(training_data4['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30fd7b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (1455563, 5000)\n",
      "y_train.shape:  (1455563,)\n",
      "X_test.shape:  (411972, 5000)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# standardize name (X, y) \n",
    "X_train = BOW_500.transform(training_data4['text'])\n",
    "y_train = training_data4['emotion']\n",
    "\n",
    "X_test = BOW_500.transform(test_data4['text'])\n",
    "\n",
    "\n",
    "#check dimension\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613ba94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  ['anger' 'anticipation' 'disgust' 'fear' 'joy' 'sadness' 'surprise'\n",
      " 'trust']\n",
      "\n",
      "## Before convert\n",
      "y_train[0:4]:\n",
      " 0         sadness\n",
      "1         disgust\n",
      "2    anticipation\n",
      "3             joy\n",
      "Name: emotion, dtype: object\n",
      "\n",
      "y_train.shape:  (1455563,)\n",
      "\n",
      "\n",
      "## After convert\n",
      "y_train[0:4]:\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      "y_train.shape:  (1455563, 8)\n"
     ]
    }
   ],
   "source": [
    "# deal with label (string -> one-hot)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "#print('y_test.shape: ', y_test.shape)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "#y_test = label_encode(label_encoder, y_test)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "#print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b3f3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  5000\n",
      "output_shape:  8\n"
     ]
    }
   ],
   "source": [
    "# I/O check\n",
    "input_shape = X_train.shape[1]\n",
    "print('input_shape: ', input_shape)\n",
    "\n",
    "output_shape = len(label_encoder.classes_)\n",
    "print('output_shape: ', output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad3caa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5000)]            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               640128    \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 707,208\n",
      "Trainable params: 707,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# building the model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax\n",
    "\n",
    "# input layer\n",
    "model_input = Input(shape=(input_shape, ))  # 500 #training data\n",
    "X = model_input\n",
    "\n",
    "# 1st hidden layer\n",
    "X_W1 = Dense(units=128)(X)  # 64 #hidden layers apply weights to the input\n",
    "H1 = ReLU()(X_W1)\n",
    "\n",
    "# 2nd hidden layer\n",
    "H1_W2 = Dense(units=128)(H1)  # 64\n",
    "H2 = ReLU()(H1_W2)          #we can change the functions, maybe gradient descent instead of RelU\n",
    "\n",
    "# 3rd hidden layer\n",
    "H2_W3 = Dense(units=128)(H2)  # 64\n",
    "H3 = ReLU()(H2_W3)          #we can change the functions, maybe gradient descent instead of RelU\n",
    "\n",
    "# 4rth hidden layer\n",
    "H3_W4 = Dense(units=128)(H3)  # 64\n",
    "H4 = ReLU()(H3_W4)          #we can change the functions, maybe gradient descent instead of RelU\n",
    "\n",
    "# 5th hidden layer\n",
    "H4_W5 = Dense(units=128)(H4)  # 64\n",
    "H5 = ReLU()(H4_W5)          #we can change the functions, maybe gradient descent instead of RelU\n",
    "\n",
    "# output layer\n",
    "H5_W6 = Dense(units=output_shape)(H5)  # 4 #emotion prediction\n",
    "H6 = Softmax()(H5_W6)\n",
    "\n",
    "model_output = H6\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "# loss function & optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# show model construction\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a55bf0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11372/11372 [==============================] - 228s 20ms/step - loss: 0.8696 - accuracy: 0.6936\n",
      "Epoch 2/10\n",
      "11372/11372 [==============================] - 260s 23ms/step - loss: 0.8679 - accuracy: 0.6944\n",
      "Epoch 3/10\n",
      "11372/11372 [==============================] - 260s 23ms/step - loss: 0.8661 - accuracy: 0.6951\n",
      "Epoch 4/10\n",
      "11372/11372 [==============================] - 272s 24ms/step - loss: 0.8643 - accuracy: 0.6958\n",
      "Epoch 5/10\n",
      "11372/11372 [==============================] - 269s 23ms/step - loss: 0.8626 - accuracy: 0.6964\n",
      "Epoch 6/10\n",
      "11372/11372 [==============================] - 267s 23ms/step - loss: 0.8611 - accuracy: 0.6969\n",
      "Epoch 7/10\n",
      "11372/11372 [==============================] - 269s 23ms/step - loss: 0.8593 - accuracy: 0.6976\n",
      "Epoch 8/10\n",
      "11372/11372 [==============================] - 268s 23ms/step - loss: 0.8579 - accuracy: 0.6981\n",
      "Epoch 9/10\n",
      "11372/11372 [==============================] - 265s 23ms/step - loss: 0.8562 - accuracy: 0.6988\n",
      "Epoch 10/10\n",
      "11372/11372 [==============================] - 270s 23ms/step - loss: 0.8548 - accuracy: 0.6994\n",
      "training finish\n"
     ]
    }
   ],
   "source": [
    "# Trainig the model\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('data/training_log2.csv') #will save our training results into .csv\n",
    "\n",
    "# training setting\n",
    "epochs = 10 #total number of iterations in one cicle\n",
    "batch_size = 128 #number of samples we pass to the network in one pass\n",
    "\n",
    "\n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[csv_logger])\n",
    "print('training finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "540da2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3219/3219 [==============================] - 16s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.63178836e-03, 1.06494427e-02, 2.17280891e-02, 1.04156928e-02,\n",
       "        7.46348619e-01, 8.19519535e-02, 7.97143653e-02, 3.95599231e-02],\n",
       "       [1.78867107e-04, 1.75515757e-04, 3.31151672e-02, 1.03566209e-02,\n",
       "        1.62285141e-04, 9.15014744e-01, 3.59923318e-02, 5.00453962e-03],\n",
       "       [9.48475972e-02, 2.21161135e-02, 3.31467986e-01, 6.32878626e-03,\n",
       "        2.13750657e-02, 4.79046285e-01, 2.78672352e-02, 1.69509742e-02],\n",
       "       [2.41411608e-02, 4.66608778e-02, 3.06905657e-01, 1.34962071e-02,\n",
       "        1.42747849e-01, 1.82823285e-01, 1.82969868e-01, 1.00255124e-01],\n",
       "       [9.98289045e-03, 4.67738276e-03, 3.60976234e-02, 1.26775410e-02,\n",
       "        8.45755577e-01, 5.92196770e-02, 4.65327920e-03, 2.69360784e-02]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "pred_result2 = model.predict(X_test, batch_size=128)\n",
    "pred_result2[:5] #this nombers are in one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08cc9e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'sadness', 'sadness', 'disgust', 'joy'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decode to words\n",
    "pred_result2 = label_decode(label_encoder, pred_result2)\n",
    "pred_result2[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a6b1310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy             156471\n",
       "sadness          81986\n",
       "disgust          56347\n",
       "anticipation     50961\n",
       "trust            30831\n",
       "fear             14328\n",
       "anger            12765\n",
       "surprise          8283\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to DF\n",
    "pred_result2_df=pd.DataFrame(pred_result2)\n",
    "pred_result2_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f17980ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving in CSV to later submit to the kaggle\n",
    "pred_result2_df.to_csv('data/nn_5000_10_1282_5l.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
